{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "We want to implement the epsilon greedy algorithm. The purpose of the algorithm is to balance exploration whit exploitation.\n",
    "\n",
    "The concept is pretty simple: the epsilon greedy algorithm will pick the best option except for epsilon times every 100 trials.\n",
    "\n",
    "Let's immagine we want to find out what is the best slot (also called multi-armed bandit) machine to play amonght 3. Each will have a certain probability of giving a prize every time we play it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "# Multi-armed bandits definitions\n",
    "nb_bandits = 3  # Number of bandits\n",
    "# We set the probability of winning for each bandit\n",
    "p_bandits = [0.45, 0.55, 0.60]\n",
    "\n",
    "\n",
    "def pull(i):\n",
    "    \"\"\"\n",
    "    Pull arm of the bandit i\n",
    "    return 1 if win, otherwise 0.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < p_bandits[i]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# The iterations where we want to plot the results\n",
    "iterations_to_plot = [1, 10, 50, 100, 500, 10000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def epsilon_greedy(q, epsilon=0.2):\n",
    "    \"\"\"\n",
    "    The epsilon greedy function that returns a random choice\n",
    "    with a probability equal to epsilon, and the best choice\n",
    "    the rest of the time.\n",
    "    \"\"\"\n",
    "    # complete here \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the trail for `n` iteration\n",
    "def run_simulation(n_iterations, iterations_to_plot, epsilon=0.2):\n",
    "\n",
    "    # Setup plot\n",
    "    fig1, axs1 = plt.subplots(3, 2, figsize=(8, 10))\n",
    "#     [ for ax in axs]\n",
    "    axs1 = axs1.flat\n",
    "    fig2, axs2 = plt.subplots(3, 2, figsize=(8, 10))\n",
    "    axs2 = axs2.flat\n",
    "\n",
    "    # The number of trials and wins will represent the prior for each\n",
    "    #  bandit with the help of the Beta distribution.\n",
    "    trials = [0.01, 0.01, 0.01]  # Number of times we tried each bandit\n",
    "    wins = [0.01, 0.01, 0.01]  # Number of wins for each bandit\n",
    "    \n",
    "    for iteration in range(1, n_iterations+1):\n",
    "        # Define the prior based on current observations\n",
    "        results = [w/t for w,t in zip(wins, trials)]\n",
    "        if iteration in iterations_to_plot:\n",
    "            ax1 = next(axs1)\n",
    "            ax1.set_xticklabels(('B1', 'B2', 'B3'))\n",
    "            ax1.bar([1, 2, 3], results)\n",
    "            ax1.set_title(f'Estimated Probability at iteration {iteration:d}')\n",
    "            ax2 = next(axs2)\n",
    "            ax2.bar([1.2, 2.2, 3.2], wins)\n",
    "#             ax2.set_ylabel('Cumulative wins', color='r')\n",
    "            ax2.set_title(f'Cumulative wins at iteration {iteration:d}')\n",
    "\n",
    "        # Use epsilon greedy to choose a bandit\n",
    "        chosen_bandit = epsilon_greedy(results, epsilon)\n",
    "        # Pull the bandit\n",
    "        x = pull(chosen_bandit)\n",
    "        # Update trials and wins (defines the posterior)\n",
    "        trials[chosen_bandit] += 1\n",
    "        wins[chosen_bandit] += x\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "run_simulation(n_iterations=10_000, iterations_to_plot=iterations_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "In a Reinforcement learning algorithm we want to balance exploration and exploitation.\n",
    "\n",
    "To achieve this using our to MAB algorithm we can decrease the number of random choice we take when we are sure about which one is the best choice. \n",
    "\n",
    "To achieve this we can gradually decrease epsilon as we are gaining more confidence on the estimated payout of each bandit.\n",
    "\n",
    "The exercise is to adapt the function ```run_simulation_decay```\n",
    "After completing the task please try different values for epsilon and epsilon_decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T14:32:52.195395Z",
     "start_time": "2019-04-30T14:32:52.070212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the trail for `n` iteration\n",
    "def run_simulation(n_iterations, iterations_to_plot, epsilon=0.2, decay=0.01):\n",
    "\n",
    "    # Setup plot\n",
    "    fig1, axs1 = plt.subplots(3, 2, figsize=(8, 10))\n",
    "    axs1 = axs1.flat\n",
    "    fig2, axs2 = plt.subplots(3, 2, figsize=(8, 10))\n",
    "    axs2 = axs2.flat\n",
    "\n",
    "    # The number of trials and wins will represent the prior for each\n",
    "    #  bandit with the help of the Beta distribution.\n",
    "    trials = [0.01, 0.01, 0.01]  # Number of times we tried each bandit\n",
    "    wins = [0.01, 0.01, 0.01]  # Number of wins for each bandit\n",
    "    \n",
    "    for iteration in range(1, n_iterations+1):\n",
    "        # Define the prior based on current observations\n",
    "        results = [w/t for w,t in zip(wins, trials)]\n",
    "        if iteration in iterations_to_plot:\n",
    "            ax1 = next(axs1)\n",
    "            ax1.set_xticklabels(('B1', 'B2', 'B3'))\n",
    "            ax1.bar([1, 2, 3], results)\n",
    "            ax1.set_title(f'Estimated Probability at iteration {iteration:d}')\n",
    "            ax2 = next(axs2)\n",
    "            ax2.bar([1, 2, 3], wins)\n",
    "            ax2.set_title(f'Cumulative wins at iteration {iteration:d}')\n",
    "\n",
    "        # Use epsilon greedy to choose a bandit\n",
    "        chosen_bandit = # complete here\n",
    "        # Pull the bandit\n",
    "        x = pull(chosen_bandit)\n",
    "        # Update trials and wins (defines the posterior)\n",
    "        trials[chosen_bandit] += 1\n",
    "        wins[chosen_bandit] += x\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "run_simulation(n_iterations=10_000, iterations_to_plot=iterations_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T14:32:52.384507Z",
     "start_time": "2019-04-30T14:32:52.316227Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = 0.5\n",
    "epsilon_decay = 0.9\n",
    "error_history = []\n",
    "epsilon_history = []\n",
    "\n",
    "for i in range(100):\n",
    "# Complete here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T14:32:53.082621Z",
     "start_time": "2019-04-30T14:32:52.460167Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "error = pd.DataFrame({'Error': error_history, 'Epsilon': epsilon_history})\n",
    "error.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T14:32:53.090287Z",
     "start_time": "2019-04-30T14:32:53.084310Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
